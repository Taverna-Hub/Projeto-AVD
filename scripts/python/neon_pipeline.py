import boto3
import psycopg2
import csv
from io import StringIO
from dotenv import load_dotenv
import os
import sys
from datetime import datetime
import hashlib

# Carregar variÃ¡veis de ambiente do arquivo .env
load_dotenv(override=True)

# ConfiguraÃ§Ãµes do AWS S3
s3_client = boto3.client(
    's3',
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    region_name=os.getenv("AWS_REGION")
)

# ConfiguraÃ§Ãµes do NEON
conn = psycopg2.connect(
    dbname=os.getenv("NEON_DB"),
    user=os.getenv("NEON_USER"),
    password=os.getenv("NEON_PASSWORD"),
    host=os.getenv("NEON_HOST"),
    port=os.getenv("NEON_PORT")
)

# FunÃ§Ã£o para inicializar o banco de dados
def initialize_database():
    """Cria as tabelas se nÃ£o existirem"""
    cursor = conn.cursor()
    try:
        # Verificar se a tabela dados_meteorologicos existe
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'dados_meteorologicos'
            );
        """)
        tabela_existe = cursor.fetchone()[0]
        
        if not tabela_existe:
            print(" Criando tabela dados_meteorologicos...")
            cursor.execute("""
                CREATE TABLE dados_meteorologicos (
                    id SERIAL PRIMARY KEY,
                    estacao VARCHAR(50),
                    data DATE,
                    hora VARCHAR(10),
                    temperatura FLOAT,
                    umidade FLOAT,
                    velocidade_vento FLOAT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(estacao, data, hora)
                );
            """)
            print("âœ“ Tabela dados_meteorologicos criada!")
        else:
            print("âœ“ Tabela dados_meteorologicos jÃ¡ existe")
            
            # Verificar e adicionar coluna hora se nÃ£o existir
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_name = 'dados_meteorologicos' 
                    AND column_name = 'hora'
                );
            """)
            coluna_hora_existe = cursor.fetchone()[0]
            
            if not coluna_hora_existe:
                print(" Adicionando coluna hora...")
                cursor.execute("""
                    ALTER TABLE dados_meteorologicos ADD COLUMN hora VARCHAR(10);
                """)
                print("âœ“ Coluna hora adicionada!")
            
            # Verificar e adicionar coluna updated_at se nÃ£o existir
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_name = 'dados_meteorologicos' 
                    AND column_name = 'updated_at'
                );
            """)
            coluna_updated_existe = cursor.fetchone()[0]
            
            if not coluna_updated_existe:
                print(" Adicionando coluna updated_at...")
                cursor.execute("""
                    ALTER TABLE dados_meteorologicos ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP;
                """)
                print("âœ“ Coluna updated_at adicionada!")
            
            # Verificar e adicionar constraint UNIQUE se nÃ£o existir
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.table_constraints 
                    WHERE table_name = 'dados_meteorologicos' 
                    AND constraint_name = 'dados_meteorologicos_estacao_data_hora_key'
                );
            """)
            constraint_existe = cursor.fetchone()[0]
            
            if not constraint_existe:
                print(" Adicionando constraint UNIQUE(estacao, data, hora)...")
                cursor.execute("""
                    ALTER TABLE dados_meteorologicos 
                    ADD CONSTRAINT dados_meteorologicos_estacao_data_hora_key 
                    UNIQUE(estacao, data, hora);
                """)
                print("âœ“ Constraint UNIQUE adicionada!")
        
        # Verificar se a tabela arquivos_processados existe
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'arquivos_processados'
            );
        """)
        tabela_arquivos_existe = cursor.fetchone()[0]
        
        if not tabela_arquivos_existe:
            print(" Criando tabela arquivos_processados...")
            cursor.execute("""
                CREATE TABLE arquivos_processados (
                    id SERIAL PRIMARY KEY,
                    arquivo_s3 VARCHAR(500) UNIQUE,
                    data_processamento TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    registros_inseridos INTEGER DEFAULT 0,
                    registros_atualizados INTEGER DEFAULT 0,
                    status VARCHAR(20)
                );
            """)
            print("âœ“ Tabela arquivos_processados criada!")
        else:
            print("âœ“ Tabela arquivos_processados jÃ¡ existe")
        
        # Criar Ã­ndices
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_estacao_data 
            ON dados_meteorologicos(estacao, data);
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_arquivo 
            ON arquivos_processados(arquivo_s3);
        """)
        
        conn.commit()
        print("âœ“ Banco de dados inicializado com sucesso!")
    except Exception as e:
        print(f"âœ— Erro ao inicializar banco de dados: {e}")
        conn.rollback()
        raise
    finally:
        cursor.close()

# FunÃ§Ã£o para verificar se arquivo jÃ¡ foi processado
def arquivo_ja_processado(arquivo_s3):
    """Verifica se o arquivo jÃ¡ foi processado com sucesso"""
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT status FROM arquivos_processados 
            WHERE arquivo_s3 = %s AND status = 'sucesso'
        """, (arquivo_s3,))
        resultado = cursor.fetchone()
        return resultado is not None
    except Exception as e:
        print(f"âœ— Erro ao verificar arquivo: {e}")
        return False
    finally:
        cursor.close()

# FunÃ§Ã£o para registrar arquivo processado
def registrar_arquivo_processado(arquivo_s3, registros_inseridos, registros_atualizados, status):
    """Registra ou atualiza o processamento de um arquivo"""
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO arquivos_processados 
                (arquivo_s3, registros_inseridos, registros_atualizados, status)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (arquivo_s3) 
            DO UPDATE SET 
                data_processamento = CURRENT_TIMESTAMP,
                registros_inseridos = EXCLUDED.registros_inseridos,
                registros_atualizados = EXCLUDED.registros_atualizados,
                status = EXCLUDED.status;
        """, (arquivo_s3, registros_inseridos, registros_atualizados, status))
        conn.commit()
    except Exception as e:
        print(f"âœ— Erro ao registrar arquivo: {e}")
        conn.rollback()
    finally:
        cursor.close()

# FunÃ§Ã£o para listar objetos no S3
def list_s3_objects(bucket_name, prefix):
    print(f"Listando objetos no bucket {bucket_name} com prefixo {prefix}...")
    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    if 'Contents' in response:
        return [obj['Key'] for obj in response['Contents']]
    else:
        print("Nenhum objeto encontrado no prefixo especificado.")
        return []

# FunÃ§Ã£o para extrair dados de um objeto no S3
def extract_from_s3(bucket_name, object_name):
    print(f"Extraindo dados do objeto {object_name} no bucket {bucket_name}...")
    response = s3_client.get_object(Bucket=bucket_name, Key=object_name)
    content = response['Body'].read()
    try:
        return content.decode('utf-8')
    except UnicodeDecodeError:
        print("Falha ao decodificar UTF-8, tentando Latin-1...")
        return content.decode('latin-1')

# FunÃ§Ã£o para carregar dados no NEON
def load_to_neon(data, arquivo_s3):
    print("Carregando dados no NEON...")
    cursor = conn.cursor()
    
    lines = data.splitlines()
    estacao = None
    header_found = False
    
    count_inserted = 0
    count_updated = 0
    
    for line in lines:
        # Extract station name from metadata
        if line.startswith("ESTACAO:"):
            parts = line.split(";")
            if len(parts) > 1:
                estacao = parts[1].strip()
            continue
            
        # Skip metadata until header
        if not header_found:
            if line.upper().startswith("DATA;HORA UTC"):
                header_found = True
            continue
            
        # Process data rows
        row = line.split(";")
        if len(row) < 19: # Ensure enough columns
            continue
            
        # Map columns
        # Data: index 0
        # Hora: index 1
        # Temperatura: index 7
        # Umidade: index 15
        # Velocidade Vento: index 18
        
        data_medicao = row[0]
        hora_medicao = row[1]  
        
        # Convert date format
        try:
            # Clean date format YYYY/MM/DD to YYYY-MM-DD
            if "/" in data_medicao:
                data_medicao = data_medicao.replace("/", "-")
            
            # Parse date
            data_obj = datetime.strptime(data_medicao, "%Y-%m-%d").date()
        except (ValueError, IndexError) as e:
            print(f"âš  Erro ao processar data: {data_medicao} - {e}")
            continue
        
        def parse_float(value):
            if not value:
                return None
            try:
                return float(value.replace(",", "."))
            except ValueError:
                return None

        temperatura = parse_float(row[7])
        umidade = parse_float(row[15])
        velocidade_vento = parse_float(row[18])
        
        try:
            # UPSERT: Insere ou atualiza se jÃ¡ existir
            cursor.execute("""
                INSERT INTO dados_meteorologicos 
                    (estacao, data, hora, temperatura, umidade, velocidade_vento, updated_at) 
                VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
                ON CONFLICT (estacao, data, hora) 
                DO UPDATE SET 
                    temperatura = EXCLUDED.temperatura,
                    umidade = EXCLUDED.umidade,
                    velocidade_vento = EXCLUDED.velocidade_vento,
                    updated_at = CURRENT_TIMESTAMP
                RETURNING (xmax = 0) AS inserted;
            """, (estacao, data_obj, hora_medicao, temperatura, umidade, velocidade_vento))
            
            result = cursor.fetchone()
            is_insert = result[0] if result else True
            
            conn.commit()
            
            if is_insert:
                count_inserted += 1
            else:
                count_updated += 1
            
            total = count_inserted + count_updated
            if total % 100 == 0:
                print(f"  âœ“ Processados: {total} (Inseridos: {count_inserted}, Atualizados: {count_updated})")
                
        except Exception as e:
            print(f"  âœ— Erro ao processar registro: {e}")
            conn.rollback()
            continue

    cursor.close()
    
    # Registrar arquivo como processado
    registrar_arquivo_processado(arquivo_s3, count_inserted, count_updated, 'sucesso')
    
    print(f"âœ“ Arquivo processado! Inseridos: {count_inserted}, Atualizados: {count_updated}, Total: {count_inserted + count_updated}")

# Pipeline principal
def main():
    bucket_name = os.getenv("AWS_BUCKET_NAME")
    prefix = os.getenv("S3_PREFIX")

    if not bucket_name or not prefix:
        print("Erro: VariÃ¡veis de ambiente AWS_BUCKET_NAME ou S3_PREFIX nÃ£o configuradas.")
        sys.exit(1)

    # Inicializar banco de dados (criar tabelas)
    print("=== Inicializando banco de dados ===")
    initialize_database()
    
    print(f"\n=== Listando objetos no bucket {bucket_name} com prefixo {prefix} ===")
    objects = list_s3_objects(bucket_name, prefix)
    
    total_arquivos = len(objects)
    processados = 0
    ignorados = 0
    
    # Processar cada objeto
    for idx, object_name in enumerate(objects, 1):
        print(f"\n[{idx}/{total_arquivos}] Verificando arquivo: {object_name}")
        
        # Verificar se arquivo jÃ¡ foi processado
        if arquivo_ja_processado(object_name):
            print(f"  â­ Arquivo jÃ¡ processado anteriormente. Pulando...")
            ignorados += 1
            continue
        
        try:
            print(f"  ðŸ“¥ Extraindo dados do S3...")
            data = extract_from_s3(bucket_name, object_name)
            
            print(f"  ðŸ’¾ Carregando no Neon...")
            load_to_neon(data, object_name)
            
            processados += 1
        except Exception as e:
            print(f"  âœ— Erro ao processar arquivo: {e}")
            registrar_arquivo_processado(object_name, 0, 0, 'erro')
            continue
    
    print(f"\n{'='*60}")
    print(f"Pipeline concluÃ­do!")
    print(f"  Total de arquivos encontrados: {total_arquivos}")
    print(f"  Arquivos processados: {processados}")
    print(f"  Arquivos ignorados (jÃ¡ processados): {ignorados}")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()