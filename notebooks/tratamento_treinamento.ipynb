{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48c2e15",
   "metadata": {},
   "source": [
    "# Tratamento e Treinamento do Modelo de Previsão de Temperatura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fb797",
   "metadata": {},
   "source": [
    "**Instala dependências e importa bibliotecas.** Carrega pandas para manipulação de dados, numpy para operações numéricas, scikit-learn para modelagem/normalização, e pickle para persistência de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O sistema n�o pode encontrar o caminho especificado.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt > /dev/null\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7721c",
   "metadata": {},
   "source": [
    "**Carrega arquivo CSV principal com tratamento de datas.** Lê arquivo CSV do INMET pulando 8 linhas de metadados, converte coluna de data/hora para índice temporal, remove colunas sem nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVISO: Arquivo não encontrado: ../data/INMET_NE_PE_A307_PETROLINA_01-01-2023_A_31-12-2023.CSV\n",
      "Por favor, coloque o arquivo CSV na pasta 'data' do projeto.\n",
      "Criando dados simulados realistas para demonstração...\n",
      "\n",
      "Dados simulados: 8760 horas (1 ano completo)\n",
      "Padrões: ciclo diário + sazonal + ruído realista\n",
      "Shape original: (8760, 5)\n",
      "Shape após limpeza: (8760, 5)\n",
      "\n",
      "Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)</th>\n",
       "      <th>UMIDADE RELATIVA DO AR, HORARIA (%)</th>\n",
       "      <th>VENTO, VELOCIDADE HORARIA (m/s)</th>\n",
       "      <th>RADIACAO GLOBAL (Kj/m²)</th>\n",
       "      <th>PRECIPITACAO TOTAL, HORARIO (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.397371</td>\n",
       "      <td>59.857062</td>\n",
       "      <td>2.560175</td>\n",
       "      <td>54.031060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.962810</td>\n",
       "      <td>44.641421</td>\n",
       "      <td>3.248457</td>\n",
       "      <td>38.936989</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.523889</td>\n",
       "      <td>41.562234</td>\n",
       "      <td>2.820707</td>\n",
       "      <td>21.925308</td>\n",
       "      <td>0.239382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.883885</td>\n",
       "      <td>47.287947</td>\n",
       "      <td>4.408418</td>\n",
       "      <td>31.894303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.752357</td>\n",
       "      <td>41.687931</td>\n",
       "      <td>2.775455</td>\n",
       "      <td>9.008618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)  \\\n",
       "0                                     26.397371   \n",
       "1                                     27.962810   \n",
       "2                                     30.523889   \n",
       "3                                     32.883885   \n",
       "4                                     32.752357   \n",
       "\n",
       "   UMIDADE RELATIVA DO AR, HORARIA (%)  VENTO, VELOCIDADE HORARIA (m/s)  \\\n",
       "0                            59.857062                         2.560175   \n",
       "1                            44.641421                         3.248457   \n",
       "2                            41.562234                         2.820707   \n",
       "3                            47.287947                         4.408418   \n",
       "4                            41.687931                         2.775455   \n",
       "\n",
       "   RADIACAO GLOBAL (Kj/m²)  PRECIPITACAO TOTAL, HORARIO (mm)  \n",
       "0                54.031060                          0.000000  \n",
       "1                38.936989                          0.000000  \n",
       "2                21.925308                          0.239382  \n",
       "3                31.894303                          0.000000  \n",
       "4                 9.008618                          0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../data/INMET_NE_PE_A307_PETROLINA_01-01-2023_A_31-12-2023.CSV\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path, \n",
    "    sep=';', \n",
    "    decimal=',', \n",
    "    encoding='latin1',\n",
    "    skiprows=8\n",
    ")\n",
    "\n",
    "print(f\"Shape original: {df.shape}\")\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "date_cols = [col for col in df.columns if 'data' in col.lower() or 'hora' in col.lower()]\n",
    "if date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    print(f\"Coluna de data identificada: '{date_col}'\")\n",
    "    try:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "        df = df.set_index(date_col)\n",
    "        df = df.sort_index()\n",
    "        print(f\"Índice temporal configurado: {df.index.min()} a {df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Aviso: Não foi possível converter coluna de data: {e}\")\n",
    "\n",
    "threshold = len(df.columns) * 0.5\n",
    "df_cleaned = df.dropna(thresh=int(threshold))\n",
    "\n",
    "print(f\"Shape após limpeza: {df_cleaned.shape}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca4d0e",
   "metadata": {},
   "source": [
    "**Carrega múltiplos CSVs para interpolação.** Busca todos os arquivos CSV da mesma estação na pasta data/ para usar como base de interpolação em períodos sem dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "csv_files = sorted(glob.glob(str(data_dir / \"*.CSV\")))\n",
    "\n",
    "print(f\"Arquivos CSV encontrados: {len(csv_files)}\")\n",
    "for f in csv_files:\n",
    "    print(f\"  - {Path(f).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b435a98",
   "metadata": {},
   "source": [
    "**Identifica e seleciona colunas relevantes.** Mapeia colunas do dataset para features padronizadas (temperatura, umidade, vento, radiação, precipitação) usando busca por palavras-chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd60bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selecionadas: ['temperatura', 'umidade', 'vento_velocidade', 'radiacao', 'precipitacao']\n",
      "Shape: (8760, 5)\n"
     ]
    }
   ],
   "source": [
    "column_keywords = {\n",
    "    'temperatura': ['bulbo seco, horaria', 'bulbo seco'],\n",
    "    'umidade': ['umidade relativa do ar, horaria'],\n",
    "    'vento_velocidade': ['velocidade horaria', 'velocidade'],\n",
    "    'vento_rajada': ['rajada maxima', 'rajada'],\n",
    "    'radiacao': ['radiacao global'],\n",
    "    'precipitacao': ['precipitacao total, horario', 'precipitacao']\n",
    "}\n",
    "\n",
    "available_cols = []\n",
    "rename_dict = {}\n",
    "\n",
    "for new_name, keywords in column_keywords.items():\n",
    "    found = False\n",
    "    for col in df_cleaned.columns:\n",
    "        col_lower = col.lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in col_lower:\n",
    "                if col not in available_cols:\n",
    "                    available_cols.append(col)\n",
    "                    rename_dict[col] = new_name\n",
    "                    found = True\n",
    "                    break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "df_features = df_cleaned[available_cols].copy()\n",
    "df_features.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "print(f\"Features selecionadas: {list(df_features.columns)}\")\n",
    "print(f\"Shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadcc84",
   "metadata": {},
   "source": [
    "**Adiciona feature engineering temporal.** Cria features derivadas (média móvel 3h, diferença temporal, hora do dia, log radiação) e remove linhas com valores ausentes remanescentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_auxiliary_data(csv_files, main_file):\n",
    "    \"\"\"Carrega dados de CSVs auxiliares para interpolação\"\"\"\n",
    "    aux_data = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        if csv_file == main_file:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df_aux = pd.read_csv(\n",
    "                csv_file,\n",
    "                sep=';',\n",
    "                decimal=',',\n",
    "                encoding='latin1',\n",
    "                skiprows=8\n",
    "            )\n",
    "            \n",
    "            df_aux = df_aux.loc[:, ~df_aux.columns.str.contains('^Unnamed')]\n",
    "            \n",
    "            date_cols = [col for col in df_aux.columns if 'data' in col.lower() or 'hora' in col.lower()]\n",
    "            if date_cols:\n",
    "                date_col = date_cols[0]\n",
    "                df_aux[date_col] = pd.to_datetime(df_aux[date_col], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "                df_aux = df_aux.set_index(date_col).sort_index()\n",
    "                aux_data.append(df_aux)\n",
    "                print(f\"  Carregado: {Path(csv_file).name} ({len(df_aux)} registros)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao carregar {Path(csv_file).name}: {e}\")\n",
    "    \n",
    "    return aux_data\n",
    "\n",
    "def interpolate_with_auxiliary_data(df_main, aux_data, feature_cols):\n",
    "    \"\"\"Interpola valores ausentes usando dados auxiliares\"\"\"\n",
    "    df_result = df_main.copy()\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        if col not in df_result.columns:\n",
    "            continue\n",
    "        \n",
    "        missing_mask = df_result[col].isnull()\n",
    "        missing_count = missing_mask.sum()\n",
    "        \n",
    "        if missing_count == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  Feature '{col}': {missing_count} valores ausentes\")\n",
    "        \n",
    "        for aux_df in aux_data:\n",
    "            if col not in aux_df.columns:\n",
    "                continue\n",
    "            \n",
    "            for idx in df_result[missing_mask].index:\n",
    "                if pd.isnull(df_result.loc[idx, col]):\n",
    "                    month = idx.month\n",
    "                    hour = idx.hour\n",
    "                    \n",
    "                    similar_data = aux_df[\n",
    "                        (aux_df.index.month == month) & \n",
    "                        (aux_df.index.hour == hour) &\n",
    "                        aux_df[col].notnull()\n",
    "                    ]\n",
    "                    \n",
    "                    if len(similar_data) > 0:\n",
    "                        df_result.loc[idx, col] = similar_data[col].median()\n",
    "        \n",
    "        still_missing = df_result[col].isnull().sum()\n",
    "        filled = missing_count - still_missing\n",
    "        \n",
    "        if filled > 0:\n",
    "            print(f\"    → Preenchidos: {filled} valores ({filled/missing_count*100:.1f}%)\")\n",
    "        \n",
    "        if still_missing > 0:\n",
    "            df_result[col] = df_result[col].interpolate(method='time', limit_direction='both')\n",
    "            final_missing = df_result[col].isnull().sum()\n",
    "            if final_missing < still_missing:\n",
    "                print(f\"    → Interpolação temporal: {still_missing - final_missing} valores adicionais\")\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "if len(csv_files) > 1:\n",
    "    print(\"\\n=== Carregando dados auxiliares para interpolação ===\")\n",
    "    aux_data = load_auxiliary_data(csv_files, file_path)\n",
    "    \n",
    "    if aux_data:\n",
    "        print(\"\\n=== Aplicando interpolação inteligente ===\")\n",
    "        available_features = [col for col in df_features.columns]\n",
    "        df_features = interpolate_with_auxiliary_data(df_features, aux_data, available_features)\n",
    "        print(f\"\\n✓ Interpolação concluída. Shape: {df_features.shape}\")\n",
    "    else:\n",
    "        print(\"\\nNenhum dado auxiliar disponível. Usando interpolação padrão.\")\n",
    "        df_features = df_features.interpolate(method='time', limit_direction='both')\n",
    "else:\n",
    "    print(\"\\nApenas 1 arquivo CSV encontrado. Usando interpolação temporal padrão.\")\n",
    "    df_features = df_features.interpolate(method='time', limit_direction='both')\n",
    "\n",
    "print(f\"\\nValores nulos remanescentes:\")\n",
    "print(df_features.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081818b0",
   "metadata": {},
   "source": [
    "**Aplica interpolação inteligente para períodos sem dados.** Identifica gaps temporais e preenche usando dados de arquivos CSV auxiliares da mesma estação, priorizando períodos correspondentes (mesmo mês/hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78476324",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'temperatura' in df_features.columns:\n",
    "    df_features['temp_media_3h'] = df_features['temperatura'].rolling(window=3, min_periods=1).mean()\n",
    "    df_features['temp_diff'] = df_features['temperatura'].diff().fillna(0)\n",
    "\n",
    "if 'radiacao' in df_features.columns:\n",
    "    df_features['radiacao_log'] = np.log1p(df_features['radiacao'])\n",
    "\n",
    "if isinstance(df_features.index, pd.DatetimeIndex):\n",
    "    df_features['hora_dia'] = df_features.index.hour\n",
    "else:\n",
    "    df_features['hora_dia'] = np.arange(len(df_features)) % 24\n",
    "\n",
    "before_dropna = len(df_features)\n",
    "df_features = df_features.dropna()\n",
    "after_dropna = len(df_features)\n",
    "\n",
    "print(f\"\\nFeatures criadas: {[c for c in df_features.columns if c in ['temp_media_3h', 'temp_diff', 'hora_dia', 'radiacao_log']]}\")\n",
    "print(f\"Linhas removidas após feature engineering: {before_dropna - after_dropna}\")\n",
    "print(f\"Shape final após tratamento: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce074ed8",
   "metadata": {},
   "source": [
    "**Remove colunas com excesso de nulos e aplica feature engineering.** Remove colunas com 50%+ nulos, aplica feature engineering temporal antes de remover linhas restantes com valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por coluna (antes):\n",
      "temperatura           0\n",
      "umidade               0\n",
      "vento_velocidade      0\n",
      "radiacao              0\n",
      "precipitacao          0\n",
      "temperatura_futura    0\n",
      "temp_media_3h         0\n",
      "temp_diff             0\n",
      "hora_dia              0\n",
      "radiacao_log          0\n",
      "dtype: int64\n",
      "\n",
      "Shape após tratamento de nulos e feature engineering: (8758, 10)\n",
      "Novas features adicionadas: temp_media_3h, temp_diff, hora_dia, radiacao_log\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores nulos por coluna (antes interpolação):\")\n",
    "print(df_features.isnull().sum())\n",
    "\n",
    "null_threshold = len(df_features) * 0.5\n",
    "cols_to_keep = [col for col in df_features.columns \n",
    "                if df_features[col].isnull().sum() < null_threshold]\n",
    "\n",
    "removed_cols = set(df_features.columns) - set(cols_to_keep)\n",
    "if removed_cols:\n",
    "    print(f\"\\nColunas removidas por excesso de nulos (>50%): {removed_cols}\")\n",
    "\n",
    "df_features = df_features[cols_to_keep]\n",
    "\n",
    "total_before = len(df_features)\n",
    "null_count_before = df_features.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nTotal de valores nulos antes do tratamento: {null_count_before}\")\n",
    "print(f\"Shape antes: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c20e4",
   "metadata": {},
   "source": [
    "**Cria variável alvo e prepara dataset para modelagem.** Gera coluna temperatura_futura usando shift(-1) para prever temperatura da próxima hora, separa features (X) e target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "121ae127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features para treinamento: ['temperatura', 'umidade', 'vento_velocidade', 'radiacao', 'precipitacao', 'temp_media_3h', 'temp_diff', 'hora_dia', 'radiacao_log']\n",
      "Total de amostras: 8757\n",
      "Shape X: (8757, 9), Shape y: (8757,)\n"
     ]
    }
   ],
   "source": [
    "df_features['temperatura_futura'] = df_features['temperatura'].shift(-1)\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "feature_cols = [c for c in df_features.columns if c != 'temperatura_futura']\n",
    "X = df_features[feature_cols]\n",
    "y = df_features['temperatura_futura']\n",
    "\n",
    "print(f\"Features para treinamento: {list(X.columns)}\")\n",
    "print(f\"Total de amostras: {len(X)}\")\n",
    "print(f\"Shape X: {X.shape}, Shape y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a0d8d",
   "metadata": {},
   "source": [
    "**Divide dados em conjuntos de treino e teste.** Usa split 80/20 sem embaralhamento (shuffle=False) para preservar ordem temporal dos dados meteorológicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54e86413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho conjunto de treino: 7005\n",
      "Tamanho conjunto de teste: 1752\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Tamanho conjunto de treino: {len(X_train)}\")\n",
    "print(f\"Tamanho conjunto de teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11657f9e",
   "metadata": {},
   "source": [
    "**Normaliza features para mesma escala.** Aplica StandardScaler para padronizar features (média 0, desvio 1), essencial quando variáveis têm escalas diferentes como radiação (~500) vs temperatura (~20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13c5c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features normalizadas com média ~0 e desvio ~1\n",
      "Shape X_train_scaled: (7005, 9)\n",
      "Shape X_test_scaled: (1752, 9)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Features normalizadas com média ~0 e desvio ~1\")\n",
    "print(f\"Shape X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"Shape X_test_scaled: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e5004",
   "metadata": {},
   "source": [
    "**Treina modelo de regressão linear e gera predições.** Ajusta LinearRegression aos dados de treino e aplica nos conjuntos de treino e teste para avaliação posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25f26614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado com sucesso (features normalizadas)\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Modelo treinado com sucesso (features normalizadas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43a331",
   "metadata": {},
   "source": [
    "**Calcula e exibe métricas de desempenho do modelo.** Computa RMSE para treino e teste e R² score, permitindo avaliar qualidade das predições e possível overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98ff394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados do Modelo de Regressão Linear ===\n",
      "RMSE (Treino): 1.3995 °C\n",
      "RMSE (Teste):  1.4537 °C\n",
      "R² Score:      0.9377\n",
      "\n",
      "Coeficientes das Features (após normalização):\n",
      "  temperatura: 15.6513\n",
      "  umidade: 0.0797\n",
      "  vento_velocidade: -0.0671\n",
      "  radiacao: 0.1664\n",
      "  precipitacao: 0.0010\n",
      "  temp_media_3h: -9.6801\n",
      "  temp_diff: -1.4802\n",
      "  hora_dia: -0.2415\n",
      "  radiacao_log: -0.0187\n",
      "  Intercepto: 26.5470\n"
     ]
    }
   ],
   "source": [
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"\\n=== Resultados do Modelo de Regressão Linear ===\")\n",
    "print(f\"RMSE (Treino): {rmse_train:.4f} °C\")\n",
    "print(f\"RMSE (Teste):  {rmse_test:.4f} °C\")\n",
    "print(f\"R² Score:      {r2_score:.4f}\")\n",
    "\n",
    "print(f\"\\nCoeficientes das Features (após normalização):\")\n",
    "for feature, coef in zip(X.columns, model.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")\n",
    "print(f\"  Intercepto: {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a914b",
   "metadata": {},
   "source": [
    "**Salva modelo e resultados para uso posterior.** Persiste modelo treinado, dados de teste, predições e métricas em arquivo pickle para carregamento no notebook de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6061cb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados salvos em 'results.pkl' (incluindo scaler)\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'y_pred_train': y_pred_train,\n",
    "    'y_pred_test': y_pred_test,\n",
    "    'rmse_train': rmse_train,\n",
    "    'rmse_test': rmse_test\n",
    "}\n",
    "\n",
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(\"Resultados salvos em 'results.pkl' (incluindo scaler)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
