{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f373f6c",
   "metadata": {},
   "source": [
    "## Importacao de Bibliotecas\n",
    "\n",
    "Carrega todas as bibliotecas necessarias para o pipeline de imputacao. O modulo `enable_iterative_imputer` deve ser importado antes do `IterativeImputer` pois este ainda e considerado experimental no scikit-learn. O `RandomForestRegressor` sera utilizado como estimador base do imputador iterativo. As bibliotecas matplotlib e seaborn sao utilizadas para visualizacao dos resultados da avaliacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0566d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, str(Path('..') / 'fastapi'))\n",
    "from services.mlflow_service import mlflow_service\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado: (526176, 27)\n",
      "Total de registros: 526,176\n",
      "Periodo: 2020-01-01 00:00:00 ate 2024-12-31 23:00:00\n",
      "Colunas alvo: ['temperatura', 'umidade', 'velocidade_vento']\n",
      "Total de features: 22\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_RATIO = 0.10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Configuracao do Pipeline de Imputacao Automatizado\")\n",
    "print(f\"  Ratio de avaliacao: {EVALUATION_RATIO * 100}%\")\n",
    "print(f\"  Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f7ee3",
   "metadata": {},
   "source": [
    "## Descoberta Automatica de Estacoes\n",
    "\n",
    "Detecta automaticamente todas as estacoes disponiveis com base nos arquivos PKL gerados pelo notebook de tratamento. O sistema busca por arquivos no formato `dados_tratados_*.pkl` e extrai os nomes das estacoes para processamento em lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_files = glob('dados_tratados_*.pkl')\n",
    "estacoes_disponiveis = []\n",
    "\n",
    "for file in dados_files:\n",
    "    estacao_name = file.replace('dados_tratados_', '').replace('.pkl', '')\n",
    "    estacoes_disponiveis.append(estacao_name)\n",
    "\n",
    "estacoes_disponiveis = sorted(estacoes_disponiveis)\n",
    "\n",
    "print(f\"\\nEstacoes detectadas: {len(estacoes_disponiveis)}\")\n",
    "for i, estacao in enumerate(estacoes_disponiveis, 1):\n",
    "    print(f\"  {i}. {estacao.replace('_', ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b037e8",
   "metadata": {},
   "source": [
    "## Inicializacao do MLflow\n",
    "\n",
    "Inicializa o servico MLflow para rastreamento de experimentos, parametros e metricas de cada estacao processada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be704329",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_service.initialize()\n",
    "\n",
    "print(f\"MLflow inicializado\")\n",
    "print(f\"  Tracking URI: {mlflow_service.tracking_uri}\")\n",
    "print(f\"  Experimento: Imputacao por Estacao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642525e3",
   "metadata": {},
   "source": [
    "## Funcao de Carregamento de Dados da Estacao\n",
    "\n",
    "Define a funcao que carrega o dataset e metadados de uma estacao especifica a partir dos arquivos PKL gerados no notebook de tratamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados_estacao(estacao_filename):\n",
    "    \"\"\"\n",
    "    Carrega dados e metadados de uma estacao.\n",
    "    \n",
    "    Args:\n",
    "        estacao_filename: Nome do arquivo da estacao (ex: 'PETROLINA')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df, metadata)\n",
    "    \"\"\"\n",
    "    pkl_filename = f'dados_tratados_{estacao_filename}.pkl'\n",
    "    metadata_filename = f'metadata_tratamento_{estacao_filename}.pkl'\n",
    "    \n",
    "    df = pd.read_pickle(pkl_filename)\n",
    "    with open(metadata_filename, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "print(\"Funcao carregar_dados_estacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a8a2d",
   "metadata": {},
   "source": [
    "## Funcao de Mascaramento para Avaliacao\n",
    "\n",
    "Define a funcao que mascara uma fracao dos valores conhecidos para avaliar a qualidade da imputacao. Esta tecnica permite comparar valores imputados com valores reais, calculando metricas de erro objetivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mascarar_dados(df, target_cols, evaluation_ratio, random_state):\n",
    "    \"\"\"\n",
    "    Mascara valores para avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com os dados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        evaluation_ratio: Percentual de dados para mascarar\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df_masked, masked_data)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    df_masked = df.copy()\n",
    "    masked_data = {}\n",
    "    \n",
    "    for col in target_cols:\n",
    "        non_null_indices = df[col].dropna().index\n",
    "        n_to_mask = int(len(non_null_indices) * evaluation_ratio)\n",
    "        mask_indices = np.random.choice(non_null_indices, size=n_to_mask, replace=False)\n",
    "        \n",
    "        masked_data[col] = {\n",
    "            'indices': mask_indices,\n",
    "            'true_values': df_masked.loc[mask_indices, col].copy()\n",
    "        }\n",
    "        df_masked.loc[mask_indices, col] = np.nan\n",
    "    \n",
    "    return df_masked, masked_data\n",
    "\n",
    "print(\"Funcao mascarar_dados() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5be95",
   "metadata": {},
   "source": [
    "## Funcao de Configuracao do Imputador\n",
    "\n",
    "Define a funcao que cria e configura o IterativeImputer com RandomForestRegressor como estimador base. Os parametros foram escolhidos para balancear qualidade de imputacao e tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_imputador(random_state):\n",
    "    \"\"\"\n",
    "    Cria e configura o IterativeImputer.\n",
    "    \n",
    "    Args:\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        IterativeImputer configurado\n",
    "    \"\"\"\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=50,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    imputer = IterativeImputer(\n",
    "        estimator=rf_estimator,\n",
    "        max_iter=10,\n",
    "        random_state=random_state,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return imputer\n",
    "\n",
    "print(\"Funcao criar_imputador() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c3a8e",
   "metadata": {},
   "source": [
    "## Funcao de Execucao da Imputacao\n",
    "\n",
    "Define a funcao que executa o processo de imputacao nos dados mascarados, preservando as colunas identificadoras (id, data, hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483209a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_imputacao(imputer, df_masked, target_cols, feature_cols):\n",
    "    \"\"\"\n",
    "    Executa a imputacao nos dados mascarados.\n",
    "    \n",
    "    Args:\n",
    "        imputer: IterativeImputer configurado\n",
    "        df_masked: DataFrame com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        feature_cols: Lista de features\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com valores imputados\n",
    "    \"\"\"\n",
    "    columns_for_imputation = target_cols + feature_cols\n",
    "    X_masked = df_masked[columns_for_imputation].copy()\n",
    "    \n",
    "    X_imputed = imputer.fit_transform(X_masked)\n",
    "    \n",
    "    df_imputed = pd.DataFrame(X_imputed, columns=columns_for_imputation, index=df_masked.index)\n",
    "    df_imputed['id'] = df_masked['id']\n",
    "    df_imputed['data'] = df_masked['data']\n",
    "    df_imputed['hora'] = df_masked['hora']\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "print(\"Funcao executar_imputacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a08a3",
   "metadata": {},
   "source": [
    "## Funcao de Calculo de Metricas\n",
    "\n",
    "Define a funcao que calcula as metricas de qualidade da imputacao comparando valores imputados com valores reais mascarados. As metricas incluem RMSE, MAE e R-quadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(df_imputed, masked_data, target_cols):\n",
    "    \"\"\"\n",
    "    Calcula metricas de avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df_imputed: DataFrame com valores imputados\n",
    "        masked_data: Dicionario com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        \n",
    "    Returns:\n",
    "        dict: Metricas de avaliacao por coluna\n",
    "    \"\"\"\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for col in target_cols:\n",
    "        indices = masked_data[col]['indices']\n",
    "        true_values = masked_data[col]['true_values']\n",
    "        imputed_values = df_imputed.loc[indices, col]\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "        mae = mean_absolute_error(true_values, imputed_values)\n",
    "        r2 = r2_score(true_values, imputed_values)\n",
    "        \n",
    "        evaluation_results[col] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "print(\"Funcao calcular_metricas() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9706366",
   "metadata": {},
   "source": [
    "## Funcao de Geracao de Visualizacao\n",
    "\n",
    "Define a funcao que gera graficos de dispersao comparando valores reais versus valores imputados para cada variavel alvo. A linha diagonal representa a predicao perfeita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_visualizacao(df_imputed, masked_data, target_cols, evaluation_results, estacao_nome, estacao_filename):\n",
    "    \"\"\"\n",
    "    Gera graficos de avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df_imputed: DataFrame com valores imputados\n",
    "        masked_data: Dicionario com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        evaluation_results: Metricas de avaliacao\n",
    "        estacao_nome: Nome da estacao\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        \n",
    "    Returns:\n",
    "        str: Caminho do arquivo de plot salvo\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Avaliacao da Imputacao - {estacao_nome}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for idx, col in enumerate(target_cols):\n",
    "        ax = axes[idx]\n",
    "        indices = masked_data[col]['indices']\n",
    "        true_values = masked_data[col]['true_values']\n",
    "        imputed_values = df_imputed.loc[indices, col]\n",
    "        \n",
    "        ax.scatter(true_values, imputed_values, alpha=0.5, s=20)\n",
    "        min_val = min(true_values.min(), imputed_values.min())\n",
    "        max_val = max(true_values.max(), imputed_values.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Valor Real', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Valor Imputado', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(\n",
    "            f\"{col.upper()}\\nRMSE: {evaluation_results[col]['RMSE']:.3f} | R2: {evaluation_results[col]['R2']:.3f}\",\n",
    "            fontsize=12, fontweight='bold'\n",
    "        )\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_plot = f'avaliacao_imputacao_{estacao_filename}.png'\n",
    "    plt.savefig(output_plot, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return output_plot\n",
    "\n",
    "print(\"Funcao gerar_visualizacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765c4d9",
   "metadata": {},
   "source": [
    "## Funcao de Exportacao de Resultados\n",
    "\n",
    "Define a funcao que exporta os resultados da imputacao para arquivos locais, incluindo o dataset completo, dados para update no banco e metricas de avaliacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_resultados(df_final, evaluation_results, estacao_filename):\n",
    "    \"\"\"\n",
    "    Exporta resultados da imputacao para arquivos.\n",
    "    \n",
    "    Args:\n",
    "        df_final: DataFrame com dados imputados finais\n",
    "        evaluation_results: Metricas de avaliacao\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        \n",
    "    Returns:\n",
    "        dict: Caminhos dos arquivos exportados\n",
    "    \"\"\"\n",
    "    df_for_update = pd.DataFrame({\n",
    "        'id': df_final['id'],\n",
    "        'data': df_final['data'],\n",
    "        'hora': df_final['hora'],\n",
    "        'temperatura': df_final['temperatura'],\n",
    "        'umidade': df_final['umidade'],\n",
    "        'velocidade_vento': df_final['velocidade_vento']\n",
    "    })\n",
    "    \n",
    "    output_pkl = f'dados_imputados_{estacao_filename}.pkl'\n",
    "    output_csv = f'dados_para_update_neon_{estacao_filename}.csv'\n",
    "    output_metrics = f'metricas_imputacao_{estacao_filename}.pkl'\n",
    "    \n",
    "    df_final.to_pickle(output_pkl)\n",
    "    df_for_update.to_csv(output_csv, index=False)\n",
    "    with open(output_metrics, 'wb') as f:\n",
    "        pickle.dump(evaluation_results, f)\n",
    "    \n",
    "    return {\n",
    "        'pkl': output_pkl,\n",
    "        'csv': output_csv,\n",
    "        'metrics': output_metrics\n",
    "    }\n",
    "\n",
    "print(\"Funcao exportar_resultados() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649692a0",
   "metadata": {},
   "source": [
    "## Funcao Principal de Processamento\n",
    "\n",
    "Define a funcao principal que orquestra todo o pipeline de imputacao para uma estacao: carregamento, mascaramento, imputacao, avaliacao, visualizacao, exportacao e registro no MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23374970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_estacao(estacao_filename, evaluation_ratio, random_state):\n",
    "    \"\"\"\n",
    "    Processa imputacao completa para uma estacao.\n",
    "    \n",
    "    Args:\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        evaluation_ratio: Percentual de dados para mascaramento\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        dict: Metricas de avaliacao\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"PROCESSANDO ESTACAO: {estacao_filename.replace('_', ' ')}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    df, metadata = carregar_dados_estacao(estacao_filename)\n",
    "    target_cols = metadata['target_cols']\n",
    "    feature_cols = metadata['feature_cols']\n",
    "    estacao_nome = metadata['estacao']\n",
    "    \n",
    "    print(f\"\\n1. Dataset carregado: {df.shape}\")\n",
    "    print(f\"   Registros: {len(df):,}\")\n",
    "    print(f\"   Periodo: {metadata['date_range'][0]} ate {metadata['date_range'][1]}\")\n",
    "    \n",
    "    df_original = df.copy()\n",
    "    df_masked, masked_data = mascarar_dados(df, target_cols, evaluation_ratio, random_state)\n",
    "    \n",
    "    print(f\"\\n2. Mascaramento para avaliacao ({evaluation_ratio*100}%):\")\n",
    "    for col in target_cols:\n",
    "        n_masked = len(masked_data[col]['indices'])\n",
    "        print(f\"   {col}: {n_masked:,} valores mascarados\")\n",
    "    \n",
    "    imputer = criar_imputador(random_state)\n",
    "    \n",
    "    print(f\"\\n3. Executando imputacao...\")\n",
    "    df_imputed = executar_imputacao(imputer, df_masked, target_cols, feature_cols)\n",
    "    \n",
    "    print(f\"\\n4. Calculando metricas de avaliacao:\")\n",
    "    evaluation_results = calcular_metricas(df_imputed, masked_data, target_cols)\n",
    "    for col in target_cols:\n",
    "        r = evaluation_results[col]\n",
    "        print(f\"   {col}: RMSE={r['RMSE']:.4f}, MAE={r['MAE']:.4f}, R2={r['R2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. Gerando visualizacao...\")\n",
    "    output_plot = gerar_visualizacao(df_imputed, masked_data, target_cols, evaluation_results, estacao_nome, estacao_filename)\n",
    "    \n",
    "    print(f\"\\n6. Imputacao final nos dados originais...\")\n",
    "    df_final = executar_imputacao(imputer, df_original, target_cols, feature_cols)\n",
    "    \n",
    "    print(f\"\\n7. Exportando resultados...\")\n",
    "    output_files = exportar_resultados(df_final, evaluation_results, estacao_filename)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n8. Registrando no MLflow...\")\n",
    "    mlflow_service.log_imputation_run(\n",
    "        station_name=estacao_nome,\n",
    "        metrics={\n",
    "            'avg_rmse': np.mean([m['RMSE'] for m in evaluation_results.values()]),\n",
    "            'avg_mae': np.mean([m['MAE'] for m in evaluation_results.values()]),\n",
    "            'avg_r2': np.mean([m['R2'] for m in evaluation_results.values()]),\n",
    "            'temperatura_rmse': evaluation_results['temperatura']['RMSE'],\n",
    "            'umidade_rmse': evaluation_results['umidade']['RMSE'],\n",
    "            'velocidade_vento_rmse': evaluation_results['velocidade_vento']['RMSE'],\n",
    "            'duration_seconds': duration\n",
    "        },\n",
    "        params={\n",
    "            'n_estimators': 50,\n",
    "            'max_depth': 10,\n",
    "            'min_samples_split': 10,\n",
    "            'min_samples_leaf': 5,\n",
    "            'max_iter': 10,\n",
    "            'evaluation_ratio': evaluation_ratio,\n",
    "            'n_records': len(df),\n",
    "            'n_features': len(feature_cols)\n",
    "        },\n",
    "        artifacts={\n",
    "            'plot': output_plot,\n",
    "            'metrics_file': output_files['metrics']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEstacao {estacao_nome} processada em {duration:.2f}s\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "print(\"Funcao processar_estacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b6927",
   "metadata": {},
   "source": [
    "## Execucao Automatica para Todas as Estacoes\n",
    "\n",
    "Loop principal que processa automaticamente todas as estacoes detectadas, registrando metricas individuais e consolidadas no MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start = time.time()\n",
    "resultados_todas_estacoes = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"INICIANDO PROCESSAMENTO DE {len(estacoes_disponiveis)} ESTACOES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, estacao_filename in enumerate(estacoes_disponiveis, 1):\n",
    "    print(f\"\\n[{i}/{len(estacoes_disponiveis)}] Processando: {estacao_filename.replace('_', ' ')}\")\n",
    "    \n",
    "    try:\n",
    "        metricas = processar_estacao(\n",
    "            estacao_filename=estacao_filename,\n",
    "            evaluation_ratio=EVALUATION_RATIO,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        resultados_todas_estacoes[estacao_filename] = metricas\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar {estacao_filename}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "total_duration = time.time() - total_start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMO GERAL DO PROCESSAMENTO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEstacoes processadas: {len(resultados_todas_estacoes)}/{len(estacoes_disponiveis)}\")\n",
    "print(f\"Tempo total: {total_duration:.2f}s ({total_duration/60:.2f} minutos)\")\n",
    "print(f\"\\nMetricas medias por variavel:\")\n",
    "\n",
    "for var in ['temperatura', 'umidade', 'velocidade_vento']:\n",
    "    rmse_values = [r[var]['RMSE'] for r in resultados_todas_estacoes.values()]\n",
    "    mae_values = [r[var]['MAE'] for r in resultados_todas_estacoes.values()]\n",
    "    r2_values = [r[var]['R2'] for r in resultados_todas_estacoes.values()]\n",
    "    \n",
    "    print(f\"\\n  {var.upper()}:\")\n",
    "    print(f\"    RMSE medio: {np.mean(rmse_values):.4f} (std: {np.std(rmse_values):.4f})\")\n",
    "    print(f\"    MAE medio: {np.mean(mae_values):.4f} (std: {np.std(mae_values):.4f})\")\n",
    "    print(f\"    R2 medio: {np.mean(r2_values):.4f} (std: {np.std(r2_values):.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETO CONCLUIDO COM SUCESSO\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
