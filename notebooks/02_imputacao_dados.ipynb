{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f373f6c",
   "metadata": {},
   "source": [
    "## Importacao de Bibliotecas\n",
    "\n",
    "Carrega todas as bibliotecas necessarias para o pipeline de imputacao. O modulo `enable_iterative_imputer` deve ser importado antes do `IterativeImputer` pois este ainda e considerado experimental no scikit-learn. O `RandomForestRegressor` sera utilizado como estimador base do imputador iterativo. As bibliotecas matplotlib e seaborn sao utilizadas para visualizacao dos resultados da avaliacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0566d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb7676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuracao do Pipeline de Imputacao Automatizado\n",
      "  Ratio de avaliacao: 10.0%\n",
      "  Random state: 42\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_RATIO = 0.10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Configuracao do Pipeline de Imputacao Automatizado\")\n",
    "print(f\"  Ratio de avaliacao: {EVALUATION_RATIO * 100}%\")\n",
    "print(f\"  Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f7ee3",
   "metadata": {},
   "source": [
    "## Descoberta Automatica de Estacoes\n",
    "\n",
    "Detecta automaticamente todas as estacoes disponiveis com base nos arquivos PKL gerados pelo notebook de tratamento. O sistema busca por arquivos no formato `dados_tratados_*.pkl` e extrai os nomes das estacoes para processamento em lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55f193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estacoes detectadas: 12\n",
      "  1. ARCO VERDE\n",
      "  2. CABROBO\n",
      "  3. CARUARU\n",
      "  4. FLORESTA\n",
      "  5. GARANHUNS\n",
      "  6. IBIMIRIM\n",
      "  7. OURICURI\n",
      "  8. PALMARES\n",
      "  9. PETROLINA\n",
      "  10. SALGUEIRO\n",
      "  11. SERRA TALHADA\n",
      "  12. SURUBIM\n"
     ]
    }
   ],
   "source": [
    "dados_files = glob('dados_tratados_*.pkl')\n",
    "estacoes_disponiveis = []\n",
    "\n",
    "for file in dados_files:\n",
    "    estacao_name = file.replace('dados_tratados_', '').replace('.pkl', '')\n",
    "    estacoes_disponiveis.append(estacao_name)\n",
    "\n",
    "estacoes_disponiveis = sorted(estacoes_disponiveis)\n",
    "\n",
    "print(f\"\\nEstacoes detectadas: {len(estacoes_disponiveis)}\")\n",
    "for i, estacao in enumerate(estacoes_disponiveis, 1):\n",
    "    print(f\"  {i}. {estacao.replace('_', ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b037e8",
   "metadata": {},
   "source": [
    "## Inicializacao do MLflow\n",
    "\n",
    "Inicializa o servico MLflow para rastreamento de experimentos, parametros e metricas de cada estacao processada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be704329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow inicializado\n",
      "  Tracking URI: http://mlflow:5000\n",
      "  Experimento: Imputacao por Estacao\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "EXPERIMENT_NAME = \"Imputacao_por_Estacao\"\n",
    "\n",
    "try:\n",
    "    exp_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "except:\n",
    "    exp_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "mlflow.set_experiment(experiment_id=exp_id)\n",
    "\n",
    "print(f\"MLflow inicializado\")\n",
    "print(f\"  Tracking URI: http://mlflow:5000\")\n",
    "print(f\"  Experimento: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642525e3",
   "metadata": {},
   "source": [
    "## Funcao de Carregamento de Dados da Estacao\n",
    "\n",
    "Define a funcao que carrega o dataset e metadados de uma estacao especifica a partir dos arquivos PKL gerados no notebook de tratamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3a8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao carregar_dados_estacao() definida\n"
     ]
    }
   ],
   "source": [
    "def carregar_dados_estacao(estacao_filename):\n",
    "    \"\"\"\n",
    "    Carrega dados e metadados de uma estacao.\n",
    "    \n",
    "    Args:\n",
    "        estacao_filename: Nome do arquivo da estacao (ex: 'PETROLINA')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df, metadata)\n",
    "    \"\"\"\n",
    "    pkl_filename = f'dados_tratados_{estacao_filename}.pkl'\n",
    "    metadata_filename = f'metadata_tratamento_{estacao_filename}.pkl'\n",
    "    \n",
    "    df = pd.read_pickle(pkl_filename)\n",
    "    with open(metadata_filename, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    return df, metadata\n",
    "\n",
    "print(\"Funcao carregar_dados_estacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a8a2d",
   "metadata": {},
   "source": [
    "## Funcao de Mascaramento para Avaliacao\n",
    "\n",
    "Define a funcao que mascara uma fracao dos valores conhecidos para avaliar a qualidade da imputacao. Esta tecnica permite comparar valores imputados com valores reais, calculando metricas de erro objetivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772d1d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao mascarar_dados() definida\n"
     ]
    }
   ],
   "source": [
    "def mascarar_dados(df, target_cols, evaluation_ratio, random_state):\n",
    "    \"\"\"\n",
    "    Mascara valores para avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com os dados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        evaluation_ratio: Percentual de dados para mascarar\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df_masked, masked_data)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    df_masked = df.copy()\n",
    "    masked_data = {}\n",
    "    \n",
    "    for col in target_cols:\n",
    "        non_null_indices = df[col].dropna().index\n",
    "        n_to_mask = int(len(non_null_indices) * evaluation_ratio)\n",
    "        mask_indices = np.random.choice(non_null_indices, size=n_to_mask, replace=False)\n",
    "        \n",
    "        masked_data[col] = {\n",
    "            'indices': mask_indices,\n",
    "            'true_values': df_masked.loc[mask_indices, col].copy()\n",
    "        }\n",
    "        df_masked.loc[mask_indices, col] = np.nan\n",
    "    \n",
    "    return df_masked, masked_data\n",
    "\n",
    "print(\"Funcao mascarar_dados() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5be95",
   "metadata": {},
   "source": [
    "## Funcao de Configuracao do Imputador\n",
    "\n",
    "Define a funcao que cria e configura o IterativeImputer com RandomForestRegressor como estimador base. Os parametros foram escolhidos para balancear qualidade de imputacao e tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b229dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao criar_imputador() definida\n"
     ]
    }
   ],
   "source": [
    "def criar_imputador(random_state):\n",
    "    \"\"\"\n",
    "    Cria e configura o IterativeImputer.\n",
    "    \n",
    "    Args:\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        IterativeImputer configurado\n",
    "    \"\"\"\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=50,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    imputer = IterativeImputer(\n",
    "        estimator=rf_estimator,\n",
    "        max_iter=10,\n",
    "        random_state=random_state,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return imputer\n",
    "\n",
    "print(\"Funcao criar_imputador() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c3a8e",
   "metadata": {},
   "source": [
    "## Funcao de Execucao da Imputacao\n",
    "\n",
    "Define a funcao que executa o processo de imputacao nos dados mascarados, preservando as colunas identificadoras (id, data, hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483209a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao executar_imputacao() definida\n"
     ]
    }
   ],
   "source": [
    "def executar_imputacao(imputer, df_masked, target_cols, feature_cols):\n",
    "    \"\"\"\n",
    "    Executa a imputacao nos dados mascarados.\n",
    "    \n",
    "    Args:\n",
    "        imputer: IterativeImputer configurado\n",
    "        df_masked: DataFrame com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        feature_cols: Lista de features\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com valores imputados\n",
    "    \"\"\"\n",
    "    columns_for_imputation = target_cols + feature_cols\n",
    "    X_masked = df_masked[columns_for_imputation].copy()\n",
    "    \n",
    "    X_imputed = imputer.fit_transform(X_masked)\n",
    "    \n",
    "    df_imputed = pd.DataFrame(X_imputed, columns=columns_for_imputation, index=df_masked.index)\n",
    "    df_imputed['id'] = df_masked['id']\n",
    "    df_imputed['data'] = df_masked['data']\n",
    "    df_imputed['hora'] = df_masked['hora']\n",
    "    \n",
    "    return df_imputed\n",
    "\n",
    "print(\"Funcao executar_imputacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a08a3",
   "metadata": {},
   "source": [
    "## Funcao de Calculo de Metricas\n",
    "\n",
    "Define a funcao que calcula as metricas de qualidade da imputacao comparando valores imputados com valores reais mascarados. As metricas incluem RMSE, MAE e R-quadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a00e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao calcular_metricas() definida\n"
     ]
    }
   ],
   "source": [
    "def calcular_metricas(df_imputed, masked_data, target_cols):\n",
    "    \"\"\"\n",
    "    Calcula metricas de avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df_imputed: DataFrame com valores imputados\n",
    "        masked_data: Dicionario com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        \n",
    "    Returns:\n",
    "        dict: Metricas de avaliacao por coluna\n",
    "    \"\"\"\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for col in target_cols:\n",
    "        indices = masked_data[col]['indices']\n",
    "        true_values = masked_data[col]['true_values']\n",
    "        imputed_values = df_imputed.loc[indices, col]\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(true_values, imputed_values))\n",
    "        mae = mean_absolute_error(true_values, imputed_values)\n",
    "        r2 = r2_score(true_values, imputed_values)\n",
    "        \n",
    "        evaluation_results[col] = {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "print(\"Funcao calcular_metricas() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9706366",
   "metadata": {},
   "source": [
    "## Funcao de Geracao de Visualizacao\n",
    "\n",
    "Define a funcao que gera graficos de dispersao comparando valores reais versus valores imputados para cada variavel alvo. A linha diagonal representa a predicao perfeita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f381b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao gerar_visualizacao() definida\n"
     ]
    }
   ],
   "source": [
    "def gerar_visualizacao(df_imputed, masked_data, target_cols, evaluation_results, estacao_nome, estacao_filename):\n",
    "    \"\"\"\n",
    "    Gera graficos de avaliacao da imputacao.\n",
    "    \n",
    "    Args:\n",
    "        df_imputed: DataFrame com valores imputados\n",
    "        masked_data: Dicionario com valores mascarados\n",
    "        target_cols: Lista de colunas alvo\n",
    "        evaluation_results: Metricas de avaliacao\n",
    "        estacao_nome: Nome da estacao\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        \n",
    "    Returns:\n",
    "        str: Caminho do arquivo de plot salvo\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Avaliacao da Imputacao - {estacao_nome}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for idx, col in enumerate(target_cols):\n",
    "        ax = axes[idx]\n",
    "        indices = masked_data[col]['indices']\n",
    "        true_values = masked_data[col]['true_values']\n",
    "        imputed_values = df_imputed.loc[indices, col]\n",
    "        \n",
    "        ax.scatter(true_values, imputed_values, alpha=0.5, s=20)\n",
    "        min_val = min(true_values.min(), imputed_values.min())\n",
    "        max_val = max(true_values.max(), imputed_values.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Valor Real', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Valor Imputado', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(\n",
    "            f\"{col.upper()}\\nRMSE: {evaluation_results[col]['RMSE']:.3f} | R2: {evaluation_results[col]['R2']:.3f}\",\n",
    "            fontsize=12, fontweight='bold'\n",
    "        )\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_plot = f'avaliacao_imputacao_{estacao_filename}.png'\n",
    "    plt.savefig(output_plot, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return output_plot\n",
    "\n",
    "print(\"Funcao gerar_visualizacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765c4d9",
   "metadata": {},
   "source": [
    "## Funcao de Exportacao de Resultados\n",
    "\n",
    "Define a funcao que exporta os resultados da imputacao para arquivos locais, incluindo o dataset completo, dados para update no banco e metricas de avaliacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2787890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao exportar_resultados() definida\n"
     ]
    }
   ],
   "source": [
    "def exportar_resultados(df_final, evaluation_results, estacao_filename):\n",
    "    \"\"\"\n",
    "    Exporta resultados da imputacao para arquivos.\n",
    "    \n",
    "    Args:\n",
    "        df_final: DataFrame com dados imputados finais\n",
    "        evaluation_results: Metricas de avaliacao\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        \n",
    "    Returns:\n",
    "        dict: Caminhos dos arquivos exportados\n",
    "    \"\"\"\n",
    "    df_for_update = pd.DataFrame({\n",
    "        'id': df_final['id'],\n",
    "        'data': df_final['data'],\n",
    "        'hora': df_final['hora'],\n",
    "        'temperatura': df_final['temperatura'],\n",
    "        'umidade': df_final['umidade'],\n",
    "        'velocidade_vento': df_final['velocidade_vento']\n",
    "    })\n",
    "    \n",
    "    output_pkl = f'dados_imputados_{estacao_filename}.pkl'\n",
    "    output_csv = f'dados_para_update_neon_{estacao_filename}.csv'\n",
    "    output_metrics = f'metricas_imputacao_{estacao_filename}.pkl'\n",
    "    \n",
    "    df_final.to_pickle(output_pkl)\n",
    "    df_for_update.to_csv(output_csv, index=False)\n",
    "    with open(output_metrics, 'wb') as f:\n",
    "        pickle.dump(evaluation_results, f)\n",
    "    \n",
    "    return {\n",
    "        'pkl': output_pkl,\n",
    "        'csv': output_csv,\n",
    "        'metrics': output_metrics\n",
    "    }\n",
    "\n",
    "print(\"Funcao exportar_resultados() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649692a0",
   "metadata": {},
   "source": [
    "## Funcao Principal de Processamento\n",
    "\n",
    "Define a funcao principal que orquestra todo o pipeline de imputacao para uma estacao: carregamento, mascaramento, imputacao, avaliacao, visualizacao, exportacao e registro no MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23374970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao processar_estacao() definida\n"
     ]
    }
   ],
   "source": [
    "def processar_estacao(estacao_filename, evaluation_ratio, random_state):\n",
    "    \"\"\"\n",
    "    Processa imputacao completa para uma estacao.\n",
    "    \n",
    "    Args:\n",
    "        estacao_filename: Nome do arquivo da estacao\n",
    "        evaluation_ratio: Percentual de dados para mascaramento\n",
    "        random_state: Seed para reproducibilidade\n",
    "        \n",
    "    Returns:\n",
    "        dict: Metricas de avaliacao\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"PROCESSANDO ESTACAO: {estacao_filename.replace('_', ' ')}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    df, metadata = carregar_dados_estacao(estacao_filename)\n",
    "    target_cols = metadata['target_cols']\n",
    "    feature_cols = metadata['feature_cols']\n",
    "    estacao_nome = metadata['estacao']\n",
    "    \n",
    "    print(f\"\\n1. Dataset carregado: {df.shape}\")\n",
    "    print(f\"   Registros: {len(df):,}\")\n",
    "    print(f\"   Periodo: {metadata['date_range'][0]} ate {metadata['date_range'][1]}\")\n",
    "    \n",
    "    df_original = df.copy()\n",
    "    df_masked, masked_data = mascarar_dados(df, target_cols, evaluation_ratio, random_state)\n",
    "    \n",
    "    print(f\"\\n2. Mascaramento para avaliacao ({evaluation_ratio*100}%):\")\n",
    "    for col in target_cols:\n",
    "        n_masked = len(masked_data[col]['indices'])\n",
    "        print(f\"   {col}: {n_masked:,} valores mascarados\")\n",
    "    \n",
    "    imputer = criar_imputador(random_state)\n",
    "    \n",
    "    print(f\"\\n3. Executando imputacao...\")\n",
    "    df_imputed = executar_imputacao(imputer, df_masked, target_cols, feature_cols)\n",
    "    \n",
    "    print(f\"\\n4. Calculando metricas de avaliacao:\")\n",
    "    evaluation_results = calcular_metricas(df_imputed, masked_data, target_cols)\n",
    "    for col in target_cols:\n",
    "        r = evaluation_results[col]\n",
    "        print(f\"   {col}: RMSE={r['RMSE']:.4f}, MAE={r['MAE']:.4f}, R2={r['R2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n5. Gerando visualizacao...\")\n",
    "    output_plot = gerar_visualizacao(df_imputed, masked_data, target_cols, evaluation_results, estacao_nome, estacao_filename)\n",
    "    \n",
    "    print(f\"\\n6. Imputacao final nos dados originais...\")\n",
    "    df_final = executar_imputacao(imputer, df_original, target_cols, feature_cols)\n",
    "    \n",
    "    print(f\"\\n7. Exportando resultados...\")\n",
    "    output_files = exportar_resultados(df_final, evaluation_results, estacao_filename)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n8. Registrando no MLflow...\")\n",
    "    \n",
    "    # Registrar no MLflow usando API direta\n",
    "    run_name = f\"{estacao_nome}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        # Tags\n",
    "        mlflow.set_tags({\n",
    "            \"station_name\": estacao_nome,\n",
    "            \"experiment_type\": \"imputation\",\n",
    "            \"method\": \"IterativeImputer\",\n",
    "            \"estimator\": \"RandomForestRegressor\"\n",
    "        })\n",
    "        \n",
    "        # Parametros\n",
    "        mlflow.log_params({\n",
    "            'n_estimators': 50,\n",
    "            'max_depth': 10,\n",
    "            'min_samples_split': 10,\n",
    "            'min_samples_leaf': 5,\n",
    "            'max_iter': 10,\n",
    "            'evaluation_ratio': evaluation_ratio,\n",
    "            'n_records': len(df),\n",
    "            'n_features': len(feature_cols)\n",
    "        })\n",
    "        \n",
    "        # Metricas\n",
    "        mlflow.log_metrics({\n",
    "            'avg_rmse': np.mean([m['RMSE'] for m in evaluation_results.values()]),\n",
    "            'avg_mae': np.mean([m['MAE'] for m in evaluation_results.values()]),\n",
    "            'avg_r2': np.mean([m['R2'] for m in evaluation_results.values()]),\n",
    "            'temperatura_rmse': evaluation_results['temperatura']['RMSE'],\n",
    "            'umidade_rmse': evaluation_results['umidade']['RMSE'],\n",
    "            'velocidade_vento_rmse': evaluation_results['velocidade_vento']['RMSE'],\n",
    "            'duration_seconds': duration\n",
    "        })\n",
    "        \n",
    "        # Artifacts\n",
    "        mlflow.log_artifact(output_plot)\n",
    "        mlflow.log_artifact(output_files['metrics'])\n",
    "    \n",
    "    print(f\"\\nEstacao {estacao_nome} processada em {duration:.2f}s\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "print(\"Funcao processar_estacao() definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b6927",
   "metadata": {},
   "source": [
    "## Execucao Automatica para Todas as Estacoes\n",
    "\n",
    "Loop principal que processa automaticamente todas as estacoes detectadas, registrando metricas individuais e consolidadas no MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df86f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INICIANDO PROCESSAMENTO DE 12 ESTACOES\n",
      "======================================================================\n",
      "\n",
      "[1/12] Processando: ARCO VERDE\n",
      "\n",
      "======================================================================\n",
      "PROCESSANDO ESTACAO: ARCO VERDE\n",
      "======================================================================\n",
      "\n",
      "1. Dataset carregado: (43848, 27)\n",
      "   Registros: 43,848\n",
      "   Periodo: 2020-01-01 00:00:00 ate 2024-12-31 23:00:00\n",
      "\n",
      "2. Mascaramento para avaliacao (10.0%):\n",
      "   temperatura: 2,830 valores mascarados\n",
      "   umidade: 2,830 valores mascarados\n",
      "   velocidade_vento: 2,819 valores mascarados\n",
      "\n",
      "3. Executando imputacao...\n",
      "\n",
      "4. Calculando metricas de avaliacao:\n",
      "   temperatura: RMSE=1.0067, MAE=0.7497, R2=0.9450\n",
      "   umidade: RMSE=4.7411, MAE=3.4234, R2=0.9346\n",
      "   velocidade_vento: RMSE=1.0596, MAE=0.8228, R2=0.4345\n",
      "\n",
      "5. Gerando visualizacao...\n",
      "\n",
      "6. Imputacao final nos dados originais...\n",
      "\n",
      "7. Exportando resultados...\n",
      "\n",
      "8. Registrando no MLflow...\n",
      "ERRO ao processar ARCO_VERDE: 'MLflowService' object has no attribute 'log_imputation_run'\n",
      "\n",
      "[2/12] Processando: CABROBO\n",
      "\n",
      "======================================================================\n",
      "PROCESSANDO ESTACAO: CABROBO\n",
      "======================================================================\n",
      "\n",
      "1. Dataset carregado: (43848, 27)\n",
      "   Registros: 43,848\n",
      "   Periodo: 2020-01-01 00:00:00 ate 2024-12-31 23:00:00\n",
      "\n",
      "2. Mascaramento para avaliacao (10.0%):\n",
      "   temperatura: 3,770 valores mascarados\n",
      "   umidade: 2,871 valores mascarados\n",
      "   velocidade_vento: 3,769 valores mascarados\n",
      "\n",
      "3. Executando imputacao...\n",
      "\n",
      "4. Calculando metricas de avaliacao:\n",
      "   temperatura: RMSE=1.2303, MAE=0.9028, R2=0.9054\n",
      "   umidade: RMSE=5.7891, MAE=3.4643, R2=0.9558\n",
      "   velocidade_vento: RMSE=1.2078, MAE=0.8103, R2=0.4607\n",
      "\n",
      "5. Gerando visualizacao...\n",
      "\n",
      "6. Imputacao final nos dados originais...\n",
      "\n",
      "7. Exportando resultados...\n",
      "\n",
      "8. Registrando no MLflow...\n",
      "ERRO ao processar CABROBO: 'MLflowService' object has no attribute 'log_imputation_run'\n",
      "\n",
      "[3/12] Processando: CARUARU\n",
      "\n",
      "======================================================================\n",
      "PROCESSANDO ESTACAO: CARUARU\n",
      "======================================================================\n",
      "\n",
      "1. Dataset carregado: (43848, 27)\n",
      "   Registros: 43,848\n",
      "   Periodo: 2020-01-01 00:00:00 ate 2024-12-31 23:00:00\n",
      "\n",
      "2. Mascaramento para avaliacao (10.0%):\n",
      "   temperatura: 2,642 valores mascarados\n",
      "   umidade: 2,585 valores mascarados\n",
      "   velocidade_vento: 2,524 valores mascarados\n",
      "\n",
      "3. Executando imputacao...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(estacoes_disponiveis)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Processando: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestacao_filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     metricas \u001b[38;5;241m=\u001b[39m \u001b[43mprocessar_estacao\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestacao_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestacao_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVALUATION_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     resultados_todas_estacoes[estacao_filename] \u001b[38;5;241m=\u001b[39m metricas\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m, in \u001b[0;36mprocessar_estacao\u001b[0;34m(estacao_filename, evaluation_ratio, random_state)\u001b[0m\n\u001b[1;32m     36\u001b[0m imputer \u001b[38;5;241m=\u001b[39m criar_imputador(random_state)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. Executando imputacao...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m df_imputed \u001b[38;5;241m=\u001b[39m \u001b[43mexecutar_imputacao\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m4. Calculando metricas de avaliacao:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m calcular_metricas(df_imputed, masked_data, target_cols)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mexecutar_imputacao\u001b[0;34m(imputer, df_masked, target_cols, feature_cols)\u001b[0m\n\u001b[1;32m     14\u001b[0m columns_for_imputation \u001b[38;5;241m=\u001b[39m target_cols \u001b[38;5;241m+\u001b[39m feature_cols\n\u001b[1;32m     15\u001b[0m X_masked \u001b[38;5;241m=\u001b[39m df_masked[columns_for_imputation]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 17\u001b[0m X_imputed \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_masked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m df_imputed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_imputed, columns\u001b[38;5;241m=\u001b[39mcolumns_for_imputation, index\u001b[38;5;241m=\u001b[39mdf_masked\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     20\u001b[0m df_imputed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_masked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/impute/_iterative.py:765\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[1;32m    762\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    763\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    764\u001b[0m     )\n\u001b[0;32m--> 765\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    774\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/impute/_iterative.py:412\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    402\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[1;32m    403\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    405\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    406\u001b[0m     )\n\u001b[1;32m    407\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[1;32m    408\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    410\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    411\u001b[0m     )\n\u001b[0;32m--> 412\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(missing_row_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_start = time.time()\n",
    "resultados_todas_estacoes = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"INICIANDO PROCESSAMENTO DE {len(estacoes_disponiveis)} ESTACOES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, estacao_filename in enumerate(estacoes_disponiveis, 1):\n",
    "    print(f\"\\n[{i}/{len(estacoes_disponiveis)}] Processando: {estacao_filename.replace('_', ' ')}\")\n",
    "    \n",
    "    try:\n",
    "        metricas = processar_estacao(\n",
    "            estacao_filename=estacao_filename,\n",
    "            evaluation_ratio=EVALUATION_RATIO,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        resultados_todas_estacoes[estacao_filename] = metricas\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao processar {estacao_filename}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "total_duration = time.time() - total_start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMO GERAL DO PROCESSAMENTO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEstacoes processadas: {len(resultados_todas_estacoes)}/{len(estacoes_disponiveis)}\")\n",
    "print(f\"Tempo total: {total_duration:.2f}s ({total_duration/60:.2f} minutos)\")\n",
    "print(f\"\\nMetricas medias por variavel:\")\n",
    "\n",
    "for var in ['temperatura', 'umidade', 'velocidade_vento']:\n",
    "    rmse_values = [r[var]['RMSE'] for r in resultados_todas_estacoes.values()]\n",
    "    mae_values = [r[var]['MAE'] for r in resultados_todas_estacoes.values()]\n",
    "    r2_values = [r[var]['R2'] for r in resultados_todas_estacoes.values()]\n",
    "    \n",
    "    print(f\"\\n  {var.upper()}:\")\n",
    "    print(f\"    RMSE medio: {np.mean(rmse_values):.4f} (std: {np.std(rmse_values):.4f})\")\n",
    "    print(f\"    MAE medio: {np.mean(mae_values):.4f} (std: {np.std(mae_values):.4f})\")\n",
    "    print(f\"    R2 medio: {np.mean(r2_values):.4f} (std: {np.std(r2_values):.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETO CONCLUIDO COM SUCESSO\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
